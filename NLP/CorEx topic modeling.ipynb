{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/botocore/vendored/requests/packages/urllib3/_collections.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, MutableMapping\n",
      "/anaconda3/lib/python3.7/site-packages/botocore/vendored/requests/packages/urllib3/_collections.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, MutableMapping\n",
      "/anaconda3/lib/python3.7/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt # jupyter notebooks will complain matplotlib is being loaded twice\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import gensim\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchored Correlation Explanation:Topic Modeling with Minimal Domain Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def describe_training_documents(list_of_docs):\n",
    "    print('There are',len(list_of_docs),'documents.')\n",
    "    document_lengths = list(map(lambda x: len(x.split()),list_of_docs))\n",
    "    percentile_50 = int(np.percentile(document_lengths,50))\n",
    "    percentile_95 = int(np.percentile(document_lengths,95))\n",
    "    print('95% of the documents are below:',percentile_95,'words.')\n",
    "    plt.axvline(percentile_50, lw=1, color='g')\n",
    "    plt.axvline(percentile_95, lw=1, color='r', linestyle='--')\n",
    "    _ = plt.hist(document_lengths, bins=50, range=(0,percentile_95+100))\n",
    "    print('Solid green line indicates median, dotted red line indicates 95 percentile. Outliers may be cropped.')\n",
    "\n",
    "def flatten_list(l):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 20 newsgroups data\n",
    "newsgroups = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "documents_train = list(np.load('./training/train.npy')) # historical materials 4451 documents\n",
    "documents_train2 = list(np.load('./training/train2.npy'))   # census bureau 4226 documents\n",
    "df_occsc = pd.read_csv('OCC_pairs.csv').rename(columns={'OCC_DES':'Full Occupation'})\n",
    "assert(df_occsc['Full Occupation'].nunique() == len(df_occsc))\n",
    "occ_list = list(set(list(df_occsc['Full Occupation'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12351 documents.\n",
      "95% of the documents are below: 110 words.\n",
      "Solid green line indicates median, dotted red line indicates 95 percentile. Outliers may be cropped.\n"
     ]
    }
   ],
   "source": [
    "with open(\"nyt_index.csv\",'r') as f:\n",
    "    nyt_text=[]\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        if len(line.split(\" \"))>70:\n",
    "            nyt_text.append(line.split('###')[1])\n",
    "\n",
    "describe_training_documents(nyt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4348 documents.\n",
      "95% of the documents are below: 66 words.\n",
      "Solid green line indicates median, dotted red line indicates 95 percentile. Outliers may be cropped.\n"
     ]
    }
   ],
   "source": [
    "with open(\"nyt_text_modified.txt\",'r') as f:\n",
    "    nyt_text2=[]\n",
    "    lines=f.readlines()\n",
    "    for line in lines:\n",
    "        nyt_text2.append(line)\n",
    "        \n",
    "describe_training_documents(nyt_text2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13025\n",
      "In the dataset there are 13461 textual documents\n",
      "And this is the first one:\n",
      " Skip to main content Search UPLOAD SIGN UP | LOG IN BOOKS VIDEO AUDIO SOFTWARE IMAGESABOUT BLOG PROJECTS HELP DONATE  CONTACT JOBS VOLUNTEER PEOPLE Search Metadata Search text contents Search TV news captions Search radio transcripts Search archived websitesAdvanced SearchSign up for freeLog inFull text of \"The practical cabinet maker and furniture designer's assistant, with essays on history of furniture, taste in design, color and materials, with full explanation of the canons of good taste in furniture ..\"See other formats^ \n",
      "436\n"
     ]
    }
   ],
   "source": [
    "# include both training and testing dataset into the vectorizer\n",
    "# but fit the model with the training dataset\n",
    "# corex model requires them to be the same shape \n",
    "documents = []\n",
    "documents.extend(documents_train)\n",
    "documents.extend(documents_train2)\n",
    "documents.extend(nyt_text2)\n",
    "\n",
    "document_total=documents[:]\n",
    "document_total.extend(occ_list)\n",
    "print(len(documents))\n",
    "print(\"In the dataset there are\", len(document_total), \"textual documents\")\n",
    "print(\"And this is the first one:\\n\", documents[0])\n",
    "print(len(occ_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topic model assumes input is in the form of a doc-word matrix, where rows are documents and columns are binary counts. We'll vectorize the dataset, take the top 10,000 words, and convert it to a sparse matrix to save on memory usage. Note, we use binary count vectors as input to the CorEx topic model.\n",
    "\n",
    "### Transform data into a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13461, 10000)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=10000, binary=True)\n",
    "doc_word = vectorizer.fit_transform(document_total)\n",
    "doc_word = ss.csr_matrix(doc_word)\n",
    "\n",
    "doc_word.shape # n_docs x m_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words that label the columns (needed to extract readable topics and make anchoring easier)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13461, 9166)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get words that label the columns (needed to extract readable topics and make anchoring easier)\n",
    "words = list(np.asarray(vectorizer.get_feature_names()))\n",
    "not_digit_inds = [ind for ind,word in enumerate(words) if not word.isdigit()]\n",
    "doc_word = doc_word[:,not_digit_inds]\n",
    "words = [word for ind,word in enumerate(words) if not word.isdigit()]\n",
    "\n",
    "doc_word.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Some words never appear (or always appear)\n"
     ]
    }
   ],
   "source": [
    "# Train the CorEx topic model with 50 topics\n",
    "topic_model = ct.Corex(n_hidden=50, words=words, max_iter=200, verbose=False, seed=1)\n",
    "topic_model.fit(doc_word[:len(documents)], words=words);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('products', 0.1888025255654615, 1.0),\n",
       " ('value', 0.17104432833212274, 1.0),\n",
       " ('establishments', 0.159174169125996, 1.0),\n",
       " ('industry', 0.13722594964816293, 1.0),\n",
       " ('total', 0.12616774927774987, 1.0),\n",
       " ('reported', 0.10721105271683387, 1.0),\n",
       " ('statistics', 0.1003487152742275, 1.0),\n",
       " ('manufacture', 0.08186723375545649, 1.0),\n",
       " ('census', 0.04899813201153747, 1.0),\n",
       " ('figures', 0.046699065427696224, 1.0)]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a single topic from CorEx topic model\n",
    "topic_model.get_topics(topic=1, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: wood,piece,inch,surface,dry,glue,mold,cut,cement,sides\n",
      "1: products,value,establishments,industry,total,reported,statistics,manufacture,census,figures\n",
      "2: fig,furniture,design,pieces,chairs,legs,designs,cabinet,panels,chair\n",
      "3: govt,repts,com,urges,pres,ct,gen,ussr,natl,rept\n",
      "4: earners,number,wage,cent,average,employed,increase,increased,proportion,largest\n",
      "5: add,hot,boil,boiling,mix,vegetables,milk,cooking,varnish,pint\n",
      "6: york,new,pennsylvania,jersey,north,south,ohio,illinois,state,district\n",
      "7: union,local,members,international,locals,organization,convention,unions,employers,executive\n",
      "8: style,century,art,taste,french,marquetry,louis,gothic,boulle,ebony\n",
      "9: age,engaged,occupations,gainful,females,persons,sex,males,years,occupational\n",
      "10: precinct,patrolmen,annum,assignments,duty,division,appointed,18th,patrolman,effect\n",
      "11: yesterday,today,washington,national,department,street,july,association,john,aug\n",
      "12: mind,life,borne,people,worker,brought,facts,influence,human,question\n",
      "13: market,exchange,prices,demand,trading,posted,stock,cable,packages,sterling\n",
      "14: operations,individual,avoid,disclosing,disclosure,includes,refining,product,furnaces,produced\n",
      "15: ladies,garment,shop,girls,movement,possible,care,men,young,better\n",
      "16: work,good,time,make,best,quite,matter,thing,simple,bring\n",
      "17: carved,carving,bronze,turned,figs,egyptian,museum,marie,antoinette,animals\n",
      "18: table,shows,according,shown,classification,classified,gives,distribution,different,given\n",
      "19: court,war,american,mr,london,supreme,justice,mrs,science,judge\n",
      "20: steel,iron,rolling,works,tons,tonnage,vessels,coal,tinplate,launched\n",
      "21: long,high,like,education,examination,college,way,society,universities,course\n",
      "22: tho,materials,cost,circulation,classes,publications,periodicals,carpets,ho,rugs\n",
      "23: world,old,home,knowledge,history,english,family,story,written,said\n",
      "24: water,turpentine,oil,rosin,produce,heat,spirits,gum,required,gallon\n",
      "25: trade,present,physical,manufacturers,health,factors,particular,called,especially,tuberculosis\n",
      "26: law,act,decision,laws,funds,program,party,million,action,legal\n",
      "27: goods,woolen,worsted,knit,wool,hosiery,jute,textiles,cordage,twine\n",
      "28: nearest,december,month,representative,day,salaries,15th,wages,months,year\n",
      "29: conditions,comparison,earlier,actual,certain,rates,report,shops,basis,commercial\n",
      "30: technology,institute,president,committee,vice,avenue,secretary,chairman,boston,park\n",
      "31: hours,prevailing,week,worked,working,wire,rods,boots,shoes,laborin\n",
      "32: ends,room,drawer,glued,upper,floor,shelves,teacher,carefully,fit\n",
      "33: used,silk,hats,leather,material,finished,use,yarn,raw,tanned\n",
      "34: states,united,leading,maximum,minimum,rank,statestable,boldface,italic,higher\n",
      "35: greater,smaller,fact,importance,employees,larger,considerable,greatest,largely,proportions\n",
      "36: industries,manufacturing,meat,packing,slaughtering,concerning,inquiry,secured,canning,preserving\n",
      "37: purpose,necessary,bad,frequently,rest,body,position,difficult,picture,length\n",
      "38: right,man,say,spirit,stand,need,things,come,shall,sort\n",
      "39: school,students,schools,problem,training,teachers,elementary,pupils,graduate,problems\n",
      "40: workers,women,occupation,living,earnings,personal,finishers,families,adequate,pursued\n",
      "41: agriculture,agricultural,bureau,domestic,exports,carriages,assigned,wagons,imports,clerical\n",
      "42: san,francisco,viii,ix,vi,palace,oakland,carpenters,discussions,crystal\n",
      "43: chinese,japanese,japan,rome,china,seen,return,greece,arrest,grew\n",
      "44: cotton,group,groups,comprising,beet,capacity,wares,types,fabrics,ments\n",
      "45: county,farm,professional,farmers,service,farms,parents,station,va,supports\n",
      "46: plan,meeting,mass,joint,press,project,permanent,test,joined,settle\n",
      "47: land,western,germany,radio,king,jobs,declared,eastern,church,canada\n",
      "48: england,clothing,published,carried,ll,shirts,distinguished,centralized,extensive,italians\n",
      "49: board,continue,chiefly,drop,ii,contracts,imported,guard,removal,furnishing\n"
     ]
    }
   ],
   "source": [
    "# Print all topics from the CorEx topic model\n",
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436, 50)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=topic_model.predict(doc_word[len(documents):])\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_result(results):\n",
    "    pairs=[]\n",
    "    for i in range(len(results)):\n",
    "        for j in range(len(results[i])):\n",
    "            if results[i][j]==True:\n",
    "                pairs.append([i,j])\n",
    "    return pairs\n",
    "\n",
    "def count_topics(pairs):\n",
    "    available={}\n",
    "    for a,b in pairs:\n",
    "        if b not in available.keys():\n",
    "            available[b]=1\n",
    "        else:\n",
    "            available[b]+=1\n",
    "    return available \n",
    "\n",
    "def get_topic_content(pairs,topic):\n",
    "    result=[]\n",
    "    for a,b in pairs:\n",
    "        if b == topic:\n",
    "            result.append(occ_list[a])\n",
    "    return result \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Corelation and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.45757782459769"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.tc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.tcs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.45757782459769\n",
      "12.45757782459769\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(topic_model.tcs))\n",
    "print(topic_model.tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting number of topics:Choosing from the data visualised\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(range(topic_model.tcs.shape[0]), topic_model.tcs, color='#4e79a7', width=0.5)\n",
    "plt.xlabel('Topic', fontsize=16)\n",
    "plt.ylabel('Total Correlation (nats)', fontsize=16);\n",
    "plt.savefig('Distribution of TCs for each topic', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise Document TC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8677, 30)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.log_z.shape # n_docs x k_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.34974539 0.83554806 0.70903774 0.70545575 0.68693023 0.56250323\n",
      " 0.53726093 0.51397045 0.50238426 0.49800946 0.44917444 0.41939602\n",
      " 0.4013495  0.37549139 0.35551906 0.3394628  0.33001975 0.31568205\n",
      " 0.29639085 0.28862444 0.27634022 0.27239563 0.24001884 0.23892719\n",
      " 0.23133722 0.22984241 0.22585549 0.21901736 0.21107025 0.20957803\n",
      " 0.19759806 0.19475075 0.18146505 0.17683385 0.17142717 0.1658273\n",
      " 0.160654   0.15995043 0.15710332 0.15364033 0.14336239 0.1335164\n",
      " 0.12901163 0.12075866 0.10256559 0.10245789 0.09818597 0.09731013\n",
      " 0.07496047 0.04938526]\n",
      "[1.34974539 0.83554806 0.70903774 0.70545575 0.68693023 0.56250323\n",
      " 0.53726093 0.51397045 0.50238426 0.49800946 0.44917444 0.41939602\n",
      " 0.4013495  0.37549139 0.35551906 0.3394628  0.33001975 0.31568205\n",
      " 0.29639085 0.28862444 0.27634022 0.27239563 0.24001884 0.23892719\n",
      " 0.23133722 0.22984241 0.22585549 0.21901736 0.21107025 0.20957803\n",
      " 0.19759806 0.19475075 0.18146505 0.17683385 0.17142717 0.1658273\n",
      " 0.160654   0.15995043 0.15710332 0.15364033 0.14336239 0.1335164\n",
      " 0.12901163 0.12075866 0.10256559 0.10245789 0.09818597 0.09731013\n",
      " 0.07496047 0.04938526]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(topic_model.log_z, axis=0)) #The pointwise total correlations in log_z represent the correlations within an individual document explained by a particular topic. These correlations have been used to measure how \"surprising\" documents are with respect to given topics\n",
    "print(topic_model.tcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Anchoring in the semi-supervised topic mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CorEx is a discriminative model, whereas LDA is a generative model. This means that while LDA outputs a probability distribution over each document, CorEx instead estimates the probability a document belongs to a topic given that document's words. As a result, the probabilities across topics for a given document do not have to add up to 1. The estimated probabilities of topics for each document can be accessed through log_p_y_given_x or p_y_given_x."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical Topic Models\n",
    "The labels attribute gives the binary topic expressions for each document and each topic. We can use this output as input to another CorEx topic model to get latent representations of the topics themselves. This yields a hierarchical CorEx topic model. Like the first layer of the topic model, one can determine the number of latent variables to add in higher layers through examination of the topic TCs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anchored CorEx is an extension of CorEx that allows the \"anchoring\" of words to topics. When anchoring a word to a topic, CorEx is trying to maximize the mutual information between that word and the anchored topic. So, anchoring provides a way to guide the topic model towards specific subsets of words that the user would like to explore.\n",
    "\n",
    "1. Anchoring a single set of words to a single topic. This can help promote a topic that did not naturally emerge when running an unsupervised instance of the CorEx topic model. For example, one might anchor words like \"snow,\" \"cold,\" and \"avalanche\" to a topic if one suspects there should be a snow avalanche topic within a set of disaster relief articles.\n",
    "\n",
    "2. Anchoring single sets of words to multiple topics. This can help find different aspects of a topic that may be discussed in several different contexts. For example, one might anchor \"protest\" to three topics and \"riot\" to three other topics to understand different framings that arise from tweets about political protests.\n",
    "\n",
    "3. Anchoring different sets of words to multiple topics. This can help enforce topic separability if there appear to be chimera topics. For example, one might anchor \"mountain,\" \"Bernese,\" and \"dog\" to one topic and \"mountain,\" \"rocky,\" and \"colorado\" to another topic to help separate topics that merge discussion of Bernese Mountain Dogs and the Rocky Mountains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wood', 'piece', 'inch'],\n",
       " ['products', 'value', 'establishments'],\n",
       " ['fig', 'furniture', 'design'],\n",
       " ['govt', 'repts', 'com'],\n",
       " ['earners', 'number', 'wage'],\n",
       " ['add', 'hot', 'boil'],\n",
       " ['york', 'new', 'pennsylvania'],\n",
       " ['union', 'local', 'members'],\n",
       " ['style', 'century', 'art'],\n",
       " ['age', 'engaged', 'occupations'],\n",
       " ['precinct', 'patrolmen', 'annum'],\n",
       " ['yesterday', 'today', 'washington'],\n",
       " ['mind', 'life', 'borne'],\n",
       " ['market', 'exchange', 'prices'],\n",
       " ['operations', 'individual', 'avoid'],\n",
       " ['ladies', 'garment', 'shop'],\n",
       " ['work', 'good', 'time'],\n",
       " ['carved', 'carving', 'bronze'],\n",
       " ['table', 'shows', 'according'],\n",
       " ['court', 'war', 'american'],\n",
       " ['steel', 'iron', 'rolling'],\n",
       " ['long', 'high', 'like'],\n",
       " ['tho', 'materials', 'cost'],\n",
       " ['world', 'old', 'home'],\n",
       " ['water', 'turpentine', 'oil'],\n",
       " ['trade', 'present', 'physical'],\n",
       " ['law', 'act', 'decision'],\n",
       " ['goods', 'woolen', 'worsted'],\n",
       " ['nearest', 'december', 'month'],\n",
       " ['conditions', 'comparison', 'earlier'],\n",
       " ['technology', 'institute', 'president'],\n",
       " ['hours', 'prevailing', 'week'],\n",
       " ['ends', 'room', 'drawer'],\n",
       " ['used', 'silk', 'hats'],\n",
       " ['states', 'united', 'leading'],\n",
       " ['greater', 'smaller', 'fact'],\n",
       " ['industries', 'manufacturing', 'meat'],\n",
       " ['purpose', 'necessary', 'bad'],\n",
       " ['right', 'man', 'say'],\n",
       " ['school', 'students', 'schools'],\n",
       " ['workers', 'women', 'occupation'],\n",
       " ['agriculture', 'agricultural', 'bureau'],\n",
       " ['san', 'francisco', 'viii'],\n",
       " ['chinese', 'japanese', 'japan'],\n",
       " ['cotton', 'group', 'groups'],\n",
       " ['county', 'farm', 'professional'],\n",
       " ['plan', 'meeting', 'mass'],\n",
       " ['land', 'western', 'germany'],\n",
       " ['england', 'clothing', 'published'],\n",
       " ['board', 'continue', 'chiefly']]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to automatically generate anchor words: for each label in a data set, \n",
    "#we find the words that have the highest mutual information with the label.\n",
    "# we took a very simple to automatically generate the anchor words to create a semi-supervised model\n",
    "anchor_words=[]\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    anchor_words.append(list(topic_words[:3]))\n",
    "\n",
    "anchor_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Some words never appear (or always appear)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9166"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anchor 'nasa' and 'space' to first topic, 'sports' and 'stadium' to second topic, so on...\n",
    "#anchor_words = [['industry', 'manufacture','worker'], ['professional','skilled','technology'], ['politics', 'government'], ['domestic','service']]\n",
    "\n",
    "anchored_topic_model = ct.Corex(n_hidden=50, seed=2)\n",
    "anchored_topic_model.fit(doc_word[:len(documents)], words=words, anchors=anchor_words, anchor_strength=6);\n",
    "len(words)\n",
    "doc_word.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: wood,piece,inch,mold,sides,surface,cut,cement,edges,inches\n",
      "1: establishments,products,value,industry,manufacture,statistics,manufactured,added,included,ownership\n",
      "2: furniture,fig,design,designs,examples,chair,construction,figs,artistic,designed\n",
      "3: govt,com,repts,urges,pres,ct,ussr,natl,conf,gen\n",
      "4: number,wage,earners,employed,average,employees,year,salaried,proprietors,classifies\n",
      "5: add,hot,boil,boiling,till,vegetables,let,cold,soft,milk\n",
      "6: new,york,pennsylvania,jersey,ohio,massachusetts,illinois,wisconsin,city,connecticut\n",
      "7: union,members,local,international,locals,membership,unions,cloakmakers,officers,strike\n",
      "8: style,art,century,decoration,taste,cabinet,ivory,gothic,louis,renaissance\n",
      "9: engaged,age,occupations,persons,gainful,sex,primarily,females,years,occupational\n",
      "10: precinct,annum,patrolmen,assignments,duty,division,appointed,18th,patrolman,effect\n",
      "11: today,yesterday,washington,ap,announced,aug,died,street,association,national\n",
      "12: life,mind,borne,estimate,described,obtained,industrytable,considering,bear,charming\n",
      "13: market,prices,exchange,demand,trading,posted,stock,packages,cable,bills\n",
      "14: individual,operations,avoid,disclosing,disclosure,figures,excluding,disclose,limits,omitted\n",
      "15: shop,garment,ladies,organization,shops,labor,employers,movement,worker,people\n",
      "16: work,time,good,best,experience,way,possible,quite,doing,performed\n",
      "17: carved,bronze,carving,gold,oak,legs,chairs,brass,seat,woods\n",
      "18: table,shows,according,shown,classification,classified,gives,distribution,separately,given\n",
      "19: american,war,court,supreme,federation,justice,society,government,judge,appeals\n",
      "20: steel,iron,rolling,works,mills,pig,furnaces,wire,copper,rods\n",
      "21: long,high,like,low,stage,destroyed,short,receptacle,massive,watch\n",
      "22: tho,materials,cost,expenses,salaries,wages,aro,ho,somo,nnd\n",
      "23: old,home,world,girl,surroundings,household,shock,saying,family,mary\n",
      "24: water,oil,turpentine,dry,mix,brush,stain,apply,varnish,shellac\n",
      "25: trade,present,physical,ailments,relation,report,unionism,fatigue,discussed,relationship\n",
      "26: law,act,decision,legal,congress,constitutional,passed,feinberg,provisions,pass\n",
      "27: goods,woolen,worsted,knit,wool,hosiery,jute,woven,cordage,rugs\n",
      "28: month,december,nearest,representative,maximum,minimum,15th,day,employment,monthstable\n",
      "29: conditions,earlier,comparison,census,introduction,purport,compare,depreciation,expensesas,censusestable\n",
      "30: president,technology,institute,schlesinger,vice,harvard,truman,intercollegiate,team,stevens\n",
      "31: week,hours,prevailing,worked,laborin,ended,overtime,flash,retail,earn\n",
      "32: room,ends,drawer,width,tenon,rails,joints,doors,mortise,framing\n",
      "33: used,silk,hats,power,horsepower,electric,quantity,fuel,engines,motors\n",
      "34: states,united,leading,state,ranked,statestable,rank,michigan,principal,rhode\n",
      "35: fact,greater,smaller,making,owing,somewhat,notwithstanding,eke,consist,vary\n",
      "36: industries,manufacturing,meat,slaughtering,packing,textile,foundries,totals,manufactures,foundry\n",
      "37: necessary,purpose,bad,use,order,pencil,object,answer,apt,figured\n",
      "38: man,right,say,woman,film,young,husband,love,thing,wrong\n",
      "39: school,schools,students,education,university,examination,universities,examinations,courses,public\n",
      "40: workers,women,occupation,men,organize,personal,factories,amalgamated,examined,return\n",
      "41: bureau,agriculture,agricultural,forestry,husbandry,animal,department,pursuits,implements,domestic\n",
      "42: san,francisco,north,viii,south,district,population,carolina,central,west\n",
      "43: chinese,japanese,japan,large,great,certain,quantities,extent,produced,production\n",
      "44: group,cotton,cent,groups,total,reported,increase,proportion,decade,increased\n",
      "45: county,farm,professional,laborers,captions,scenes,township,contents,search,content\n",
      "46: plan,meeting,mass,annual,held,lynn,metz,revere,advancement,attended\n",
      "47: land,western,germany,london,france,europe,mr,paris,german,country\n",
      "48: england,clothing,published,circulation,publications,periodicals,newspapers,mens,dailies,shirts\n",
      "49: board,chiefly,continue,executive,joint,arbitration,grievance,dispute,railway,referendum\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(anchor_words)):\n",
    "    topic_words,_,_ = zip(*anchored_topic_model.get_topics(topic=n))\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.12767619300558\n",
      "58.12767619300558\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(anchored_topic_model.tcs))\n",
    "print(anchored_topic_model.tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436, 50)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=topic_model.predict(doc_word[13025:])\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{36: 192, 30: 97, 40: 52, 11: 81, 17: 17, 16: 15, 21: 18, 45: 54, 41: 33, 25: 11, 9: 28, 0: 4, 39: 13, 13: 7, 15: 25, 37: 13, 1: 3, 33: 3, 20: 14, 2: 2, 42: 19, 14: 6, 22: 2, 26: 3, 23: 4, 27: 9, 8: 5, 6: 2, 7: 4, 48: 11, 4: 2, 34: 5, 5: 2, 32: 1, 19: 4, 24: 1, 44: 1, 12: 1, 31: 1, 29: 1}\n",
      "['Trade Bankers, brokers, and money lenders Commercial brokers and commission men', 'Domestic and Personal Service Porters, except in stores Restaurant, cafe, and lunch room keepers', 'Domestic and Personal Service Porters, except in stores Porters, domestic and professional service', 'Trade Bankers, brokers, and money lenders Loan brokers and loan company officials', 'Trade Bankers, brokers, and money lenders Pawnbrokers', 'Manufacturing and Mechanical Industries Laborers, other metal industries Tinware, enamel-ware, etc., factories', 'Trade Bankers, brokers, and money lenders Brokers not specified and promoters', 'Trade Retail dealers Curios, antiques, and novelties', 'Trade Bankers, brokers, and money lenders Clerks in stores', 'Trade Bankers, brokers, and money lenders Stockbrokers', 'Domestic and Personal Service Porters, except in stores Porters -- steam railroad', 'Trade Bankers, brokers, and money lenders Commercial travelers', 'Manufacturing and Mechanical Industries Semiskilled operatives, other metal industries Tinware, enamel-ware, etc., factories', 'Trade Bankers, brokers, and money lenders Decorators, drapers, and window dressers', 'Trade Bankers, brokers, and money lenders Bankers and bank officials', 'Trade Laborers in coal and lumber yards, warehouses, etc. Laborers, porters, and helpers in stores', 'Domestic and Personal Service Porters, except in stores Other porters, except in stores']\n"
     ]
    }
   ],
   "source": [
    "pairs=get_predict_result(results)\n",
    "print(count_topics(pairs))\n",
    "print( get_topic_content(pairs,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_list(pairs):\n",
    "    result={}\n",
    "    for a,b in pairs:\n",
    "        if b not in result.keys():\n",
    "            result[b]=[a]\n",
    "        else:\n",
    "            result[b].append(a)\n",
    "    return result\n",
    "\n",
    "def save_topic(pairs):\n",
    "    result_dic=get_topic_list(pairs)\n",
    "    with open(\"train_result.txt\",'w') as f:\n",
    "        for m,n in result_dic.items():\n",
    "            topic_words,_,_ = zip(*anchored_topic_model.get_topics(topic=m))\n",
    "            title=str(m)+\":\"+(','.join(topic_words))\n",
    "            f.write(title+'\\n')\n",
    "            for file in n:\n",
    "                occ_title=occ_list[file]\n",
    "                f.write(occ_title+'\\n')\n",
    "            f.write(\"\\n \\n \\n\")\n",
    "\n",
    "save_topic(pairs)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
